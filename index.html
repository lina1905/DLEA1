<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <title>Bilderkennung mit ml5.js</title>
  <link rel="stylesheet" href="style.css">
  <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@400;700&display=swap" rel="stylesheet">
</head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.2/p5.min.js"></script>
<script src="https://unpkg.com/ml5@0.12.2/dist/ml5.min.js"></script>
<script src="https://cdn.plot.ly/plotly-2.20.0.min.js"></script>
<script src="script.js" defer></script>
<body>
<header>
  <h1>Bilderkennung mit <span class="highlight">ml5.js</span></h1>
  <p>Diese Webanwendung klassifiziert Bilder mithilfe eines vor-trainierten KI-Modells über die Bibliothek ml5.js direkt im Browser.<br>
    Die drei wahrscheinlichsten Klassen werden mit ihren Confidence-Werten (Wahrscheinlichkeiten) als Balkendiagramm dargestellt.
  </p>
  <p><em>Es kann einige Sekunden dauern, bis die Ergebnisse geladen werden.</em></p>
</header>

<main>
  <section class="classification-section">
    <div class="box-information">
      <h2>Richtige Klassifikationen</h2>
      <p>Die nachfolgenden drei Bilder werden richtig klassifiziert.</p>
      <div class="image-chart-pair">
        <img src="bilder/richtig1.png" alt="Bild eines Golden Retrievers" id="img1">
        <canvas id="canvas1"></canvas>
      </div>
      <div class="image-chart-pair">
        <img src="bilder/richtig2.png" alt="Bild eines Flugzeugs am Himmel" id="img2">
        <canvas id="canvas2"></canvas>
      </div>
      <div class="image-chart-pair">
        <img src="bilder/richtig3.png" alt="Bild eines Schnellzugs" id="img3">
        <canvas id="canvas3"></canvas>
      </div>
    </div>
  </section>

  <section class="classification-section">
    <div class="box-information">
      <h2>Falsche Klassifikationen</h2>
      <p>Die nachfolgenden drei Bilder werden falsch klassifiziert.</p>
      <div class="image-chart-pair">
        <img src="bilder/falsch1.png" alt="Bild eines Entenkükens" id="img4">
        <canvas id="canvas4"></canvas>
      </div>
      <div class="image-chart-pair">
        <img src="bilder/falsch2.png" alt="Bild einer Kiwi" id="img5">
        <canvas id="canvas5"></canvas>
      </div>
      <div class="image-chart-pair">
        <img src="bilder/falsch3.png" alt="Bild eines Rennautos" id="img6">        <canvas id="canvas6"></canvas>
      </div>
    </div>
  </section>

  <section class="user-upload box-information">
    <h2>Eigenes Bild hochladen</h2>
    <p>Hier kann ein Bild hochgeladen werden, welches klassifiziert werden soll.</p>
    <input type="file" id="imageUpload" accept="image/*">
    <div id="drag-and-drop-area">
      <p>Ziehe ein Bild hierher, um es zu klassifizieren.</p>
    </div>
    <div class="image-chart-pair" style="display: none;">
      <div id="user-image-preview"></div>
      <canvas id="user-chart"></canvas>
    </div>
    <button id="classifyButton">Classify</button>
    <button id="resetButton" style="display: none">Zurücksetzen</button>
  </section>

  <section class="discussion box-information">
    <h2>Diskussion</h2>
    <p>
      Die Analyse der Bildklassifikation zeigt deutlich, dass das Modell bei typischen, klar strukturierten Motiven
      mit eindeutigem Kontext sehr zuverlässige Ergebnisse liefert. So wurden ein Golden Retriever, ein Flugzeug am
      Himmel und ein Schnellzug im Bahnhof mit über 90 % Wahrscheinlichkeit korrekt erkannt, was auf eine gute
      Trainingsbasis
      und effektive Mustererkennung hindeutet. Auffällig ist dabei, dass die Top-1-Ergebnisse stark dominiert haben, während alternative Klassen nur mit sehr niedrigen Wahrscheinlichkeiten vertreten waren.
    </p>
    <p>
      Im Gegensatz dazu zeigt sich bei den Fehlklassifikationen, dass das Modell vor allem dann Schwierigkeiten hat,
      wenn ungewöhnliche Perspektiven, neutraler Hintergrund oder wenig repräsentative Merkmale vorliegen.
      Beispielsweise wurde ein Entenküken als weißer Fuchs oder Pomeranian interpretiert, vermutlich aufgrund
      ähnlicher Farb- und Formmuster. Besonders deutlich wird die Bedeutung des Kontexts am Beispiel der Kiwi, die
      mit über 50 % als Nautilus klassifiziert wurde – hier fehlt dem Modell offenbar das Verständnis für die reale
      Objektnatur. Auch das Rennauto wurde fälschlich klassifiziert, was auf Schwierigkeiten mit perspektivischer
      Erkennung und Bewegungsunschärfe hinweist.
    </p>
    <p>
      Insgesamt zeigt sich, dass der Kontext sowie die Trainingsdatenvielfalt entscheidend für die Klassifikationsgenauigkeit sind. Fehlklassifikationen bieten dabei wertvolle Einblicke in die Grenzen und Funktionsweise solcher Modelle.
    </p>
  </section>

  <section class="documentation box-information">
    <h2>Dokumentation</h2>
    <h3>Technisch</h3>
    <p>
      Verwendete Frameworks:
    <ul>
    <li><strong>ml5.js</strong>: Ein benutzerfreundliches JavaScript-Framework, das maschinelles Lernen im Browser ermöglicht. Es verwendet das vortrainierte MobileNet-Modell zur Bildklassifikation, wodurch ohne eigene Modelltrainings solide Ergebnisse erzielt werden können.

    </li>
      <li><strong>Plotly.js</strong>: Diese Visualisierungsbibliothek wird verwendet, um die Klassifikationsergebnisse als übersichtliche Balkendiagramme darzustellen. Die Darstellung der Top-3-Klassen pro Bild mit prozentualem Confidence-Wert erfolgt optisch ansprechend.
      </li>
      <li><strong>HTML5/JS/CSS</strong>: Diese Technologien bilden die Grundlage der Anwendung – sie strukturieren die Seite, steuern die Interaktionen und gestalten die Benutzeroberfläche.
      </li>
    </ul>
    <p>Besonderheiten:</p>
    <ul>
      <li>
        Die Anwendung erlaubt es, eine bereits durchgeführte Klassifikation zurückzusetzen und ein neues Bild hochzuladen. Dies wird über einen „Zurücksetzen“-Button umgesetzt, der Bildvorschau und Diagramm entfernt und eine neue Klassifikation ermöglicht – ideal für wiederholte Tests.
      </li>
      <li>
        Nutzer können Bilder sowohl per Dateiauswahl als auch durch Drag-and-Drop hochladen, was eine flexible und benutzerfreundliche Bedienung unterstützt.
      </li>
      <li>
        Beim Hochladen von Dateien per Dateiauswahl als auch über die Drag-and-Drop-Funktion wird geprüft, ob es
        sich um ein unterstütztes Bildformat (z. B. JPG, PNG) handelt. Falls kein gültiges Bild erkannt wird,
        erscheint eine entsprechende Fehlermeldung. Dies schützt vor falschen Eingaben.
      </li>
      <li>
        Um die Usability und das Verständnis der Nutzer zu verbessern, wurden jedem Funktionsbereich der Anwendung (z. B. richtige/falsche Klassifikationen, Benutzer-Upload) erklärende Texte hinzugefügt. Diese beschreiben die Funktion und den Zweck des jeweiligen Abschnitts und helfen besonders unerfahrenen Nutzern beim Einstieg.
      </li>
    </ul>
    <h3>Fachlich</h3>
    <p>
      Die Anwendung verfolgt das Ziel, die Leistungsfähigkeit und Grenzen moderner Bildklassifikationssysteme anhand eines Beispiels (MobileNet) sichtbar zu machen.
      Der fachliche Ansatz beruht darauf, dem Nutzer die Funktionsweise sowie die Stärken und Schwächen eines solchen Modells erfahrbar zu machen – durch unmittelbares visuelles Feedback
      und bewusst gewählte Beispielbilder.
    </p>

    <p>
      Ein zentraler Bestandteil ist die Darstellung der drei wahrscheinlichsten Klassifikationen eines Bildes. Diese werden dem Nutzer nicht nur textlich, sondern auch grafisch vermittelt,
      um ein besseres Verständnis über die Unsicherheiten der Vorhersage zu ermöglichen. Die Gewichtung der „Confidence“-Werte zeigt dabei, wie sicher sich das Modell in seiner Einschätzung ist,
      was eine wichtige Orientierungshilfe für die Einordnung der Ergebnisse darstellt.
    </p>

    <p>
      Zur Verdeutlichung der Grenzen des Modells wurden gezielt auch Bilder integriert, die zu Fehlklassifikationen führen. Dies unterstreicht, dass neuronale Netze wie MobileNet in bestimmten Situationen –
      etwa bei schlechter Bildqualität, untypischen Perspektiven oder fehlendem Kontext – falsche Schlüsse ziehen. Solche Fehlklassifikationen sind kein Fehler der Anwendung,
      sondern ein zentraler Punkt der Diskussion: Sie zeigen die Grenzen statistischer Mustererkennung auf und machen den Nutzer für die Risiken rein automatisierter Entscheidungen sensibel.
    </p>

    <p>
      Die Klassifikationen basieren auf dem ImageNet-Datensatz, einem der größten und am weitesten verbreiteten Bilddatensätze zur Objekterkennung.
    </p>

    <p>
      Abschließend eröffnet die Anwendung auch einen Ausblick: Sie zeigt nicht nur, was heute mit bestehenden Modellen möglich ist, sondern auch, wo noch Potenzial für Weiterentwicklungen liegt –
      etwa durch die Kombination mehrerer Modelle oder durch gezielte Trainingsdatenerweiterung für spezifische Anwendungsdomänen.
    </p>

  </section>
</main>
</body>
</html>
